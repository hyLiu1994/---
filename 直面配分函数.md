# 主要目的
无向图模型中，所有节点整体表现为概率分布，但是使用配分函数进行归一化。
本节目的主要是如何处理含有配分函数的参数优化问题。
## 问题定义
假设 
$$\left\{\begin{array}{cc} 
x \in \mathcal{R}^p & 若 x 连续\\
x \in \left\{0, 1\right\}^p & 若 x 离散(这里应该是指示变量)
\end{array}\right.$$
$$
P(x;\theta) = \frac{1}{z(\theta)} \hat{P}(X;\theta), z(\theta) = \int \hat{P}(X;\theta)dX
$$
容易知道，配分函数是只和参数有关的函数，所以相对于 样本 x 是一个常量。
需要解决的是 如何估计参数 $\theta$ 的问题
## 对数似然函数的梯度(log-likelihood function) 
使用极大似然思想求解上述问题，可得如下推导
$$
\begin{aligned}
\hat{\theta} &= \arg \max_{\theta}P(X;\theta)\\
&= \arg \max_{\theta} \prod_{i=1}^N P(x_i;\theta)\\
&= \arg \max_{\theta} \log \prod_{i=1}^N P(x_i;\theta)\\
&= \arg \max_{\theta}  \sum_{i=1}^N \log P(x_i;\theta)\\
&= \arg \max_{\theta}  \sum_{i=1}^N \log \hat{P}(x_i;\theta) - N \cdot \log z(\theta)\\
&= \arg \max_{\theta}  \underbrace{\frac{1}{N} \sum_{i=1}^N \log \hat{P}(x_i;\theta) - \log z(\theta)}_{L(\theta)}\\
\end{aligned}
$$
$$
\begin{aligned}
&\nabla_{\theta} L(\theta)  = \underbrace{\frac{1}{N} \sum_{i=1}^N \nabla_{\theta} \log \hat{P}(x_i;\theta)}_{A} - \underbrace{\nabla_{\theta}\log z(\theta) }_{B}\\
&\text{下面希望通过化简来消去表达式中的}z(\theta)\\
B & = \frac{1}{z(\theta)} \nabla_{\theta} z(\theta)\\
& = \frac{1}{z(\theta)} \nabla_{\theta} z(\theta)\\
& = \frac{P(X;\theta)}{\hat{P}(X;\theta)} \nabla_{\theta} \int \hat{P}(X;\theta)dX\\
& = \frac{P(X;\theta)}{\hat{P}(X;\theta)}  \int \nabla_{\theta}\hat{P}(X;\theta)dX\\
& 由于 \frac{P(X;\theta)}{\hat{P}(X;\theta)} 只和 \theta 有关\\
& = \int \frac{P(X;\theta)}{\hat{P}(X;\theta)}\nabla_{\theta}\hat{P}(X;\theta)dX\\
& = \int P(X;\theta)\nabla_{\theta}\log \hat{P}(X;\theta)dX\\
& = E_{P(X;\theta)}\left[\nabla_{\theta}\log \hat{P}(X;\theta)\right]\\
\end{aligned}
$$
所以样本 梯度下降 Batch gradient
分布样本 梯度下降 minor gradient
## 随机最大似然(stochastic maximum likelihood)
### 问题定义
通过上节推导，问题定义可以如下表示
$$
\begin{aligned}
& \text{Given text: } X = \left\{x_i\right\}_{i=1}^N, \text{Estimate} \theta.\\
& \left\{\begin{array}{c}\hat{\theta} = \arg \max_{\theta} L(\theta)\\
L(\theta) = \frac{1}{N}\sum_{i=1}^N \log \hat{P}(x_i;\theta) - \log z(\theta)\\ \end{array}\right.
\end{aligned}
$$
对于 $\frac{1}{N}\sum_{i=1}^N \log \hat{P}(x_i;\theta)$ 可以看作对真实分布进行采样，获取了 $N$ 个样本，所以
$$
\frac{1}{N}\sum_{i=1}^N \log \hat{P}(x_i;\theta) = E_{P_{data}}\left[\hat{P}(x_i;\theta)\right]
$$
结合上节推导
$$
\begin{aligned}
&\nabla_{\theta} L(\theta)  = \frac{1}{N} \sum_{i=1}^N \nabla{\theta} \log \hat{P}(x_i;\theta) - E_{P(X;\theta)}\left[\nabla_{\theta}\log \hat{P}(X;\theta)\right]\\
&\Rightarrow \nabla_{\theta} L(\theta)  = E_{P_{data}}\left[\hat{P}(x_i;\theta)\right] - E_{P(X;\theta)}\left[\nabla_{\theta}\log \hat{P}(X;\theta)\right]\\
\end{aligned}
$$
又因为 $P(X;\theta)$ 为估计的模型，所以可以得出如下结果
$$
\nabla_{\theta} L(\theta)  = E_{P_{data}}\left[\hat{P}(x_i;\theta)\right] - E_{P_{model}}\left[\nabla_{\theta}\log \hat{P}(X;\theta)\right]
$$
然后通过梯度上升优化参数
$$
\theta^{(t+1)} = \theta^{(t)} - \eta \nabla_{\theta} L(\theta^{(t)})
$$
对于 关于 $P_{model}$ 的期望，需要使用采样进行估计,例如
使用 Gibbs sampling 从 $P_{model}$ 采样 M 个样本。
$$
\begin{aligned}
\hat{x}_1 &\sim P(X;\theta^{(t)})\\
\hat{x}_2 &\sim P(X;\theta^{(t)})\\
&\vdots\\
\hat{x}_M &\sim P(X;\theta^{(t)})\\
\end{aligned}
$$
从估计的分布中采样的样本又叫做 Fancy particle.
最后，对于梯度上升，形式如下
$$
\theta^{(t+1)} = \theta^{(t)} - \eta \left( \sum_{i=1}^M \nabla{\theta} \log \hat{P}(x_i;\theta) -  \sum_{i=1}^M \nabla{\theta} \log \hat{P}(\hat{x}_i;\theta)\right)
$$
前后两个期望的主要区别在于使用的数据来自的分布不同，前者，来自 真实样本分布；后者，来自 估计的分布。
## 对比散度（Contrastive Divergence）
### 对比散度主要思想
原Gibbs sampling 的缺点: 达到平稳分布需要较长时间（无向图分布过于复杂）
对比散度主要想法是： 依据真实分布设定采样的初始值，依此来缩小 Gibbs sampling 的混合时间
### t+1 时刻采样
(1) 从P_{data} 中直接获取真实分布的样本
$x_1, x_2, \cdots, x_m$ 均来自训练样本
(2) 从P_{model} 估计分布中采样 $P_{model} = P(X; \theta^{(t)})$
Gibbs 采样的方法 主要有两种：第一种；可以构建一条马氏链，达到平稳分布后，采样M个所需样本；第二种; 是可以从M条马氏链同时采样，可以节约时间,但同时也消耗更多资源。下图所示为第二种。 
![xx](./markdown_figure/13_对比散度.png)
**对比散度主要在初始化时刻，直接从真实分布中获取数据作为初始值（真实分布与估计分布足够接近,所以混合时间缩短.普通的Gibbs采样一般从一个均匀分布或高斯分布采样作为初始值）**
引入对比散度后，不再约束**一定需要到平稳分布才可以采样**，甚至可以迭代一步即可获取可用的样本。通常把后移k步的对比散度叫做CD-k(k=1, 2, ...)
### 对比散度解释
首先，极大似然思想下，我们可以得出估计参数的方法如下
$$
\begin{aligned}
\hat{\theta} &= \arg \max_{\theta} \frac{1}{N} \sum_{i=1}^N log P(x_i;\theta)\\
&= \arg \max_{\theta} E_{P_{data}}\left[\log P_{model}(x; \theta)\right]\\
&= \arg \max_{\theta} \int P_{data} \log P_{model} d x\\
&= \arg \max_{\theta} \int P_{data} \log \frac{P_{model}}{P_{data}} d x\\
&= \arg \max_{\theta} - KL \left(P_{model} || P_{data}\right)\\
&= \arg \min_{\theta} KL \left(P_{model} || P_{data}\right)\\
& \text{这里引入Gibbs采样的符号}\\
&= \arg \min_{\theta} KL \left(P^{(0)} || P^{(\infty)}\right), P^{(\infty)} 表示经过长时间迭代获取的平稳分布\\
\end{aligned}
$$
也即是
$$
\hat{\theta} = \arg \min_{\theta} KL \left(P^{(0)} || P^{(\infty)}\right)
$$
通常也把上述参数优化方式称为 ML learning.
引入对比散度后，优化目标如下
$$
\hat{\theta} = \arg \min_{\theta} \underbrace{\left[KL \left(P^{(0)} || P^{(k)}\right)- KL \left(P^{(k)} || P^{(\infty)}\right)\right]}_{对比散度}
$$
通常把引入对比散度的优化方式称为 CD-learning.

## RBM学习问题
受限的玻尔兹曼机定义如下
$$
\begin{aligned}
&h = (h_1, h_2, \cdots, h_m)^T\\
&v = (v_1, v_2, \cdots, v_n)^T\\
&W = [w_{ij}]_{m \times n}\\
&\alpha = \left[\alpha_1, \alpha_2, \cdots, \alpha_n \right]\\
&\beta = \left[\beta_1, \beta_2, \cdots, \beta_m \right]\\
&\left\{\begin{array}{c}
P(h, v) = \frac{1}{z}  \exp \left\{-E(h, v)\right\} \\
E(h, v) = - (h^Twv + \alpha^T v + \beta^T h)\end{array}  \right.\\
\end{aligned}
$$
由于受限玻尔兹曼机含有隐变量，所以不能直接使用前面的结论。
极大似然估计如下
$$
\begin{aligned}
\theta = \left\{w, \alpha, \beta \right\}\\
\hat{\theta} = \arg \max_{\theta}  \sum_{v \in S} \log P(v)\\
\end{aligned}
$$
极大似然估计求解如下
$$
\begin{aligned}
&\begin{aligned}
\log P(v) &= \log \sum_{h} P(h, v) = \log \sum_{h} \frac{1}{z} \exp \left\{- E(h, v)\right\}\\
&= \log \sum_{h} \exp \left\{- E(h, v)\right\} - \log z\\
&= \underbrace{\log \sum_{h} \exp \left\{- E(h, v)\right\}}_{A} -\underbrace{\log \sum_{h, v} \exp \left\{- E(h, v)\right\}}_{B}\\
\end{aligned}\\
&\text{求导}\\
&\frac{\partial \log P(v)}{\partial \theta} = \frac{\partial }{\partial \theta} A - \frac{\partial }{\partial \theta} B \\
&\begin{aligned}
\frac{\partial }{\partial \theta} A &= \frac{\partial}{\partial \theta} \log \sum_{h} \exp \left\{-E(h, v) \right\}\\
&=-\frac{1}{\sum_{h} \exp \left\{-E(h, v) \right\}} \sum_{h} \exp \{-E(h, v)\} \frac{\partial }{\partial \theta} E(h, v)\\
& \sum_{h} \exp \{-E(h, v)\} 与 h 无关,所以 \\
&=-  \sum_{h} \frac{\exp \{-E(h, v)\}}{\sum_{h} \exp \left\{-E(h, v) \right\}} \frac{\partial }{\partial \theta} E(h, v)\\
& z 与 h 无关,所以 \\
&=-  \sum_{h} \frac{\frac{1}{z} \exp \{-E(h, v)\}}{\sum_{h} \frac{1}{z}\exp \left\{-E(h, v) \right\}} \frac{\partial }{\partial \theta} E(h, v)\\
&=-  \sum_{h} \frac{P(h, v)}{\sum_{h} P(h, v)} \frac{\partial }{\partial \theta} E(h, v)\\
&=-  \sum_{h} P(h|v)\frac{\partial }{\partial \theta} E(h, v)\\
\end{aligned}\\
&\begin{aligned}
&\frac{\partial}{\partial \theta} B = \frac{\partial}{\partial \theta}\log \sum_{h, v} \exp \left\{- E(h, v)\right\}\\
&= - \frac{1}{\sum_{h, v} \exp\left\{- E(h, v)\right\}} \sum_{h, v} \exp\left\{- E(h, v)\right\}\frac{\partial}{\partial \theta} E(h, v)\\
&= - \sum_{h, v} \frac{\exp\left\{- E(h, v)\right\}}{\sum_{h, v} \exp\left\{- E(h, v)\right\}} \frac{\partial}{\partial \theta} E(h, v)\\
&= - \sum_{h, v} \frac{\frac{1}{z} \exp\left\{- E(h, v)\right\}}{\sum_{h, v} \frac{1}{z} \exp\left\{- E(h, v)\right\}} \frac{\partial}{\partial \theta} E(h, v)\\
&= - \sum_{h, v} \frac{1}{z} \exp\left\{- E(h, v)\right\} \frac{\partial}{\partial \theta} E(h, v)\\
&= - \sum_{h, v} P(h, v)\frac{\partial}{\partial \theta} E(h, v)
\end{aligned}\\
& 综上\\
&\frac{\partial \log P(v)}{\partial \theta} = \sum_{h, v} P(h, v)\frac{\partial}{\partial \theta} E(h, v) - \sum_{h} P(h|v)\frac{\partial }{\partial \theta} E(h, v)
\end{aligned}
$$
### RBM 参数 $W_{ij}$ 的梯度
由上节推导
$$
\begin{aligned}
&\frac{\partial \log P(v)}{\partial \theta} = \sum_{h, v} P(h, v)\frac{\partial}{\partial \theta} E(h, v) - \sum_{h} P(h|v)\frac{\partial }{\partial \theta} E(h, v) \\
& \because  E(h, v) = - (h^Twv + \Delta) = - (\sum_{i=1}^M \sum_{j=1}^N h_i w_{ij} v_j + \Delta)\\
& \therefore \frac{\partial}{\partial w_{ij}} \log P(v) = - \sum_{h} P(h|v) \cdot (-h_i v_j) + \sum_{h, v}P(h, v) \cdot (-h_iv_j) = \underbrace{\sum_{h} P(h|v) \cdot (h_i v_j)}_{A} - \underbrace{\sum_{h, v}P(h, v) \cdot (h_iv_j)}_{B}\\
&\begin{aligned}
A &= \sum_{h1} \cdots \sum_{h_i} \cdots \sum_{h_m} P(h_1, h_2, \cdots, h_i, \cdots, h_m | v) \cdot h_i v_j\\
&= \sum_{h_i} P(h_i|v) v_j\\
&因为 h_i, v_j \in {0, 1}\\
&= P(h_i=1|v) v_j
\end{aligned}\\
&\begin{aligned}
B &= \sum_{h} \sum_{v} P(v)P(h|v) \cdot h_i v_j\\
 &= \sum_{v} P(v)\sum_{h} P(h|v) \cdot h_i v_j\\
 &= \sum_{v} P(v) P(h_i = 1|v) v_j\\
\end{aligned}\\
& 对于 A 由 RBM的推导，可知是可以写出解析解的,但是对于B无法写出解析解，只能通过采样的方式估计。
\end{aligned}
$$
### RBM的对比散度算法
![xx](./markdown_figure/14_RBM采样.png)
如图所示，采样流程如下
$$
\begin{aligned}
&\text{For} \quad \text{each}\quad v \in S:\\
&\qquad v^{(0)} \leftarrow v\\
&\qquad For\quad l=0, 1, 2, \cdots, k-1:\\
&\qquad \qquad For\quad i=1, 2, \cdots, m: \text{sample } h_{i}^{(l)} \sim P(h_i|v^{(l)})\\
&\qquad \qquad For\quad j=1, 2, \cdots, n: \text{sample } v_{j}^{(l+1)} \sim P(v|h^{(l)})\\
&\qquad For \quad i = 1, 2, \cdots, m; j=1, 2, \cdots, n:\\
&\qquad \qquad \Delta w_{ij} =\Delta w_{ij} + \frac{\partial}{\partial w_{ij}} \log P(v)\\
&其中 \frac{\partial}{\partial w_{ij}} \log P(v) \approx P(h_i=1|v^{(0)}) v_j^{(0)} - P(h_i=1|v^{(k)}) v_j^{(k)}\\
& 这里的 \Delta w_{ij} 是对N个样本的梯度累计。\\
& 所以对于似然函数梯度\\
& \frac{\partial }{\partial w_{ij}} \frac{1}{N} \sum_{v \in S} \log P(v) = \frac{1}{N} \sum_{v \in S} \frac{\partial }{\partial w_{ij}} \log P(v) \approx \frac{1}{N} \Delta w_{ij}\\
\end{aligned}
$$
**疑问**
$$
\begin{aligned} &\frac{\partial}{\partial w_{ij}} \log P(v) = P(h_i=1|v) v_j - \sum_{v} P(v) P(h_i = 1|v) v_j  \\
&= P(h_i=1|v) v_j - E_{P(v)}[P(h_i = 1|v) v_j]
\end{aligned}
$$
