* 受限的玻尔兹曼机(RBM)
** 背景
Boltzman Machine(玻尔兹曼机): Markov RandomField with hidden nodes.

#+BEGIN_SRC ditaa :file  ./Figure/RBM_intro.png
                                 +--> observed variable (v)
  nodes ---> random variable ----+
                                 +--> hidden variable (h)
#+END_SRC

#+RESULTS:
[[file:./Figure/RBM_intro.png]]

*** 玻尔兹曼模型定义  
一个无向概率图模型中势函数取指数族分布，那么该模型为玻尔兹曼机，所服从的分布被称为 玻尔兹曼分布（Gibbs 分布）。

玻尔兹曼机因子分解:
\begin{equation}
\label{eq:10}
\begin{align}
P \left( x \right) &= \frac{1}{Z} \prod\limits_{ i=1 }^ { K }  \varphi \left( x_{c_i} \right)\\
&= \frac{1}{Z} \prod\limits_{ i=1 }^ { K } \exp \left\{ - E \left( x_{c_i} \right) \right\}\\
&= \frac{1}{Z} exp \left\{ - \sum\limits_{i=1}^K E \left( x_{c_i} \right) \right\}
\end{align}
\end{equation}
其中 $P(x) = \frac{1}{Z} \exp \left\{ -E \left( x \right) \right\}$ 为玻尔兹曼分布（Gibbs 分布）。

**** 玻尔兹曼分布
*玻尔兹曼分布最早来源于统计物理学.*

一个物理系统(包含多个粒子, 电子或原子)状态会如下公式所示:
\begin{equation}
\label{eq:1}
P \left( state \right) \propto \exp \left\{ - \frac{E}{k\cdot T} \right\}
\end{equation}
其中 $E$ 表示系统的能量函数.

*** 概率图模型总结
#+BEGIN_SRC ditaa :file ./Figure/PGMModel.png

          Naive Bayes        <-------------    NB     ----------> 朴素贝叶斯假设
                                               |
                                               |
                                               V
    Gaussian Mixture Model   <-------------   GMM     ----------> 引入了隐变量
                                               |
                                               |
                                               V            +----> HMM
        State Space Model    <-------------   SSM     --+---+----> Kalman Filter         +---> 引入隐变量
                                               |        |   +----> Particle Filter       |                       +--> 齐次 Markov
                   LR   ---->   MEM   ---------+        +-------------------------------+---> Two assumptions --+
                                               |                                                                +--> 观测独立
                                               V                 +------>  判别模型
  Maximum Entropy Markov Model <-----------   MEMM     ----------+ 
                                               |                 +------>  打破了观测独立
                                               | 
                                               V                 +------>  判别模型
  Conditional Random Field    <-----------    CRF      ----------+------>  无向 （MRF） 
                                               |                 +------>  打破了齐次马尔科夫
                                               | 
                                               V 
  Linear Chain-CRF            <-----------   LC-CRF    ----------------->  假设无向图为链式结构 
                                               | 
                                               | 
                                               V                 +------>  无向
  Boltzman Machine            <-----------     BM      ----------+------>  引入隐变量 
                                               |                 +------>  pdf： 指数族分布
                                               | 
                                               V                 +------>   BM
  Restricted BM               <-----------    RBM      ----------+ 
                                                                 +------>  条件独立性 (假设隐变量之间，观察量之间互相条件独立)  
  
#+END_SRC

#+RESULTS:
[[file:./Figure/PGMModel.png]]
v 1个r.v   一个种类分布的参数: $\sum\limits_{i=1}^n v_i = 1$
v p个r.v   p个伯努利分布的参数, 第i个伯努利分布的参数为 $v_i$  $\sum\limits_{i=1}^p v_i \in [0,p]$ $v_i \in [0,1]$ 
**** 概率图模型的五大特点
1. 方向 (有向/无向)  ----- 边
2. 离散/连续/混合 ----- 点
3. 条件独立性强弱 (各种条件独立性假设) ----- 边
4. 隐变量 (是否包含隐变量) ----- 点
5. 概率密度函数 （是否是指数族分布) ----- 结构


** 核心思想
Boltzman Machine 难点在于 Inference, 精确推断 untrackable, 近似推断计算量有过于巨大。
因此，我们将其简化, 假设h, v 之间有连接， h,v 内部无连接。

\begin{align*}
X &= \left (
\begin{array}{c}
x_{1} \\
x_2 \\
\dots \\
x_p
\end{array}
\right )  = \left (
\begin{array}{c}
h \\
v \\
\end{array}
\right ),
h = \left (
\begin{array}{c}
h_{1} \\
h_2 \\
... \\
h_m
\end{array}
\right )
,  v = \left (
\begin{array}{c}
v_{1} \\
v_2 \\
... \\
v_n
\end{array}
\right )
, m+n = p
\end{align*}

基于以上假设，可以简化 $p \left( x \right)$:
\begin{align*}
p \left( x \right) &= \frac{1}{Z} \exp \left\{ - E \left( x \right) \right\}\\
p \left( v, h \right) &= \frac{1}{Z} \exp \left\{ -E \left( v, h \right) \right\}\\
&= \frac{1}{Z} \exp \left\{ h^T w v + \alpha^T v + \beta^T h \right\}\\
&= \frac{1}{Z} \exp \left\{ h^T w v \right\} \exp \left( \alpha^T v \right) \exp \left ( \beta^T h \right )\\
\end{align*}
其中 $E \left( v, h \right) &= - \left( h^T w v + \alpha^T v + \beta^T h \right)$ .

** RBM-Representation
\begin{align*}
\text{RBM's pdf } \rightarrow p \left( x \right) &= p \left( v, h \right) = \frac{1}{Z} \exp \left( h^T w v \right) \exp \left( \alpha^T v \right)\\
&= \frac{1}{Z} \prod\limits_{ i=1 }^ { m } \prod\limits_{ j=1 }^ { n } \exp \left( h_i w_{ij} v_j \right) \prod\limits_{ j=1 }^ { n } \exp \left( \alpha_j v_j\right) \prod\limits_{ i=1 }^ { m } \exp \left( \beta_i h_i \right)
\end{align*}
