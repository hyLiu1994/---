# 数学基础
## 马氏距离(Mahalanobis Distance)  
https://blog.csdn.net/bluesliuf/article/details/88862918
马氏距离（Mahalanobis Distance）是由马哈拉诺比斯（P. C. Mahalanobis）提出的，表示数据的协方差距离。它是一种有效的计算两个未知样本集的相似度的方法。与欧氏距离不同的是它考虑到各种特性之间的联系。

对于一个均值为 $\mu = (\mu_1, \mu_2, \mu_3,...,\mu_p)^T$ ，协方差矩阵为 $S$ 的多变量 $x = (x_1, x_2, x_3, ..., x_p)^T$ ，其马氏距离为：
$
\begin{aligned}
D_M \left( x \right) = \sqrt{\left( x-\mu \right)^T S^{-1} \left( x - \mu \right)}
\end{aligned}$
$\Sigma = I$, 马氏距离 = 欧氏距离
## Jensen's Inequality 杰森不等式
假设 $f \left( x \right)$ 是 convex functon。
则 $E[f(x)] \geqslant f(E[x])$
### 证明
$$
\begin{aligned}
&l \left( x \right) = ax + b \\
&\because f \left( x \right) \quad is \quad convex \\
&\therefore \forall x, f \left( x \right) \geqslant l \left( x \right) \\
\end{aligned}
$$
$$
\begin{aligned}
E \left[ f \left( x \right) \right] &\geqslant E \left[ l \left( x \right) \right] \\
&= E \left[ zx + b \right]\\
&= E \left[ ax \right] + E \left[ b \right]
&= a \cdot E \left[ x \right] + b \\
&= f \left( E \left[ x \right] \right)\\
\end{aligned}
$$
$\therefore E \left[ f \left( x \right) \right] \geqslant f \left( E \left[ x \right] \right)$
### 杰森不等式的常用表达
$$
\begin{aligned}
& t \in \left( 0,1 \right)\\
& c = b - t(b-a)\\
& c = ta + (1-t)*b\\
& g \left( c \right) = t f \left( a \right) + \left( 1 - t \right) f \left( b \right)\\
& t f \left( a \right) + \left( 1 - t \right) f \left( b \right) \geqslant f \left( ta + \left( 1 - t \right) b \right)
\end{aligned}
$$
$t$ 为概率，左侧为$E[f(x)]$ ，右侧为x的期望 $f(E[x])$

### 杰森不等式直觉上的解释
对于任意凸函数，对应的y值的均值大于等于其对应x值的均值对应的函数值
## 拉格朗日乘数法（待学习）
