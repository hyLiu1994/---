[toc]
# 变分推断公式推导 (variable inference)
$$
\begin{aligned}
&\log p(x|\theta) = \underbrace{ \int_{z} q(z) \log \frac{p(x, z | \theta)}{q(z)} d z}_{ELBO(evidence\ lower\ bound)} \underbrace{- \int_{z} q(z) \log \frac{p(z|x, \theta)}{q(z)} d z}_{KL \left[q(z)||p(z|x, \theta\right)]}\\
&\log p(x|\theta) = ELBO + KL \left[q(z)||p(z|x, \theta\right)]\\
&\log p(x|\theta) = L(q) + KL(q||p), \text{其中 }  KL(q||p) \geq 0 
\end{aligned}
$$
我们需要求出最优的 $q(z)$ 去拟合后验 $p(z|x)$
$$\begin{aligned}
& \hat{q}(z) = \arg \max_{q(z)} \mathcal{L}(q) \\
& \Rightarrow \hat{q}(z) \approx p(z|x) \\
& \text{根据 mean theory}\text{, 我们把 z 分为 M 组， 组与组之间相互独立，假设}\\
& q(z) = \prod^{M}_{i=1} q_i(z_i), \text{其中}, q_i(z_i) 之间相互独立\\
& \mathcal{L}(q) = \underbrace{\int_z q(z) \log p(x, z)d z}_{(1)} - \underbrace{\int_z q(z) \log q(z) d z}_{(2)}\\
& \text{对于(1)}\\
& (1) = \int \prod^M_{i=1}q_i(z_i) \log p(x, z) \quad d z_1 d z_2 \cdots d z_M \\
& \text{我们尝试分离出 } z_j \\
& \Rightarrow \int q_j(z_j) \left \{ \int \prod^M_{i=1, i \neq j}q_i(z_i) \log p(x, z) \quad d z_1 d z_2 \cdots d z_M \right\} d z_j \\
& \Rightarrow \int q_j(z_j) \quad E_{\prod^M_{i=1, i \neq j} q_i(z_i)} [\log p(x, z)] d z_j \\
& \\
& \text{对于 (2)} \\
& \int q(z) \log q(z) d z \\
& \Rightarrow \int\prod^M_{j=1} q_j(z_j)  \sum^{M}_{i=1} \log q_i(z_i) d z \\
& \Rightarrow \sum^{M}_{i=1} \int  \prod^M_{j=1} q_j(z_j)  \log q_i(z_i) d z \\
& \Rightarrow \sum^{M}_{i=1} \int  \prod^M_{j=1} q_j(z_j)  \log q_i(z_i) d z_1 d z_2 \cdots d z_M \\
& \Rightarrow \sum^{M}_{i=1} \left[\int q_i(z_i) \log q_i(z_i) d z_i  \cdot \int  \prod^M_{j=1, j \neq i} q_j(z_j) d z_1 d z_2 \cdots d z_M \right] \\
& \Rightarrow \sum^{M}_{i=1} \left[\int q_i(z_i) \log q_i(z_i) d z_i  \cdot  \prod^M_{j=1, j \neq i} \int  q_j(z_j) d z_j \right]\\
& \Rightarrow \sum^{M}_{i=1} \int q_i(z_i) \log q_i(z_i) d z_i  \\
& \text{分离出} z_j \\
& \Rightarrow  \int q_j(z_j) \log q_j(z_j) d z_j + C\\
& \text{由此可得} \\
& \text{(1)} = \int q_j(z_j) \quad E_{\prod^M_{i=1, i \neq j} q_i(z_i)} [\log p(x, z)] d z_j \\
& \text{(2)} = \int q_j(z_j) \log q_j(z_j) d z_j + C \\
& \text{由于} E_{\prod^M_{i=1, i \neq j} q_i(z_i)} [\log p(x, z)]  \text{为关于} z_j \text{的函数,  假设}\\
& \log \hat{p}(x, z_j) = E_{\prod^M_{i=1, i \neq j} q_i(z_i)} [\log p(x, z)] \\
& \text{由} L(q) = (1) - (2) 得 \\
& L(q) = \int q_j(z_j)  \log \frac{\hat{p}(x, z_j)}{q_j(z_j)} d z_j + C \\
& \text{忽略常数} C \\
& \Rightarrow L(q) = - KL[q_j(z_j) || \hat{p}(x, z_j)] \\
& \Rightarrow q_j(z_j) =  \hat{p}(x, z_j)\\
& \text{因此} q_j(z_j) 的解为 \hat{p}(x, z_j)\\
& \text{也即是}\\
& q_j(z_j) = \hat{p}(x, z_j) = \int \prod^M_{i=1, i \neq j}q_i(z_i) \log p(x, z) \quad d z_1 d z_2 \cdots d z_M 
\end{aligned}$$

# VI 算法的步骤
这里对符号作进一步说明: $x$ 指的是其中一个 数据。假设 $X$ 为整体数据， $x_i$ 为单个数据，因为数据之间的是独立同分布的，所以
$$
\arg \max \log p(X|\theta) =  \arg \max \log \prod^{N}_{i=1} p(x_i|\theta)  = \arg \max \sum^{N}_{i=1} \log  p(x_i|\theta)
$$
也即是, 我们需要去最大化每一个数据。所以下面的推导 我们用小写的 $x$ 去估计代表某个数据。
由前节推导可知
$$
q_j(z_j) = \hat{p}(x, z_j) = \int \prod^M_{i=1, i \neq j}q_i(z_i) \log p(x, z) \quad d z_1 d z_2 \cdots d z_M 
$$
所以VI 求解步骤如下:
$$
\begin{aligned}
&\hat{q}_1(z_1) = \int q_2(z_2)  q_3(z_3) q_M(z_M)  \log p(x, z) \quad  d z_2 \cdots d z_M  \\
&\hat{q}_2(z_2) = \int \hat{q}_1(z_1)  q_3(z_3)  q_M(z_M)  \log p(x, z) \quad  d z_2 \cdots d z_M  \\
& \vdots \\
&\hat{q}_i(z_i) = \int \hat{q}_1(z_1) \cdots \hat{q}_{i-1}(z_{i-1}) \cdots q_{i+1}(z_{i+1}) \cdots q_M(z_M) \log p(x, z) \quad  d z_1  \cdots d z_{i-1} d z_{i+1} \cdots d z_M  \\
& \vdots \\
&\hat{q}_M(z_M) = \int \hat{q}_1(z_1)  \hat{q}_2(z_2)  \cdots  \hat{q}_{M-1}(z_{M-1})  \log p(x, z) \quad  d z_1 \cdots d z_{M-1}  \\
\end{aligned}
$$
这里采用**坐标上升**的思想，优化一个，固定其他部分。
# 随机梯度变分推断
前节推导的变分推断的解决办法采用了**坐标上升**的思想。本节采用 随机上升的思想 解决该问题。
假定$q_{\phi}(z)$ 分布形式已知，只需求出参数$\phi$即可获取最优的$q_{\phi}(z)$ ，因此
$$
\begin{aligned}
&\because \mathcal{L}(q) = \int_z q(z) \left[ \log p(x, z) - \log q(z) \right] d z\\
&\therefore \mathcal{L}(\phi) = \int_z q_{\phi}(z) \left[ \log p(x, z) - \log q_{\phi}(z) \right] d z\\
&\text{对} \phi \text{求梯度 得}\\
& \Rightarrow \nabla_{\phi}  \mathcal{L}(\phi) = \nabla_{\phi}  \int_z q_{\phi}(z) \left[ \log p(x, z) - \log q_{\phi}(z) \right] d z\\
& \Rightarrow \nabla_{\phi}  \mathcal{L}(\phi) = \int_z \nabla_{\phi}  \left[ q_{\phi}(z) \left[ \log p(x, z) - \log q_{\phi}(z) \right] \right]d z\\
& \Rightarrow \nabla_{\phi}  \mathcal{L}(\phi) = \int_z \nabla_{\phi}   q_{\phi}(z) \left[ \log p(x, z) - \log q_{\phi}(z) \right] - q_{\phi}(z) \left[\frac{1}{q_{\phi}(z)}  \nabla_{\phi} q_{\phi}(z)\right]d z\\
& \Rightarrow \nabla_{\phi}  \mathcal{L}(\phi) = \int_z \nabla_{\phi}   q_{\phi}(z) \left[ \log p(x, z) - \log q_{\phi}(z) \right] - \int_z \nabla_{\phi} q_{\phi}(z)d z\\
& \Rightarrow \nabla_{\phi}  \mathcal{L}(\phi) = \int_z \nabla_{\phi}   q_{\phi}(z) \left[ \log p(x, z) - \log q_{\phi}(z) \right] d z - \nabla_{\phi} \int_z  q_{\phi}(z)d z\\
& \Rightarrow \nabla_{\phi}  \mathcal{L}(\phi) = \int_z \nabla_{\phi}   q_{\phi}(z) \left[ \log p(x, z) - \log q_{\phi}(z) \right] d z - \nabla_{\phi} 1\\
& \Rightarrow \nabla_{\phi}  \mathcal{L}(\phi) = \int_z \nabla_{\phi}   q_{\phi}(z) \left[ \log p(x, z) - \log q_{\phi}(z) \right] d z\\
& \text{由前节推导可知}\\
& \nabla_{\phi}   q_{\phi}(z)  = q_{\phi}(z) [\nabla_{\phi} \log q_{\phi}(z)]\\
& \Rightarrow \nabla_{\phi}  \mathcal{L}(\phi) = \int_z q_{\phi}(z)\left\{ [\nabla_{\phi} \log q_{\phi}(z)] \left[ \log p(x, z) - \log q_{\phi}(z) \right] \right\} d z\\
& \Rightarrow \nabla_{\phi}  \mathcal{L}(\phi) = E_{q_{\phi}(z) } \left\{ [\nabla_{\phi} \log q_{\phi}(z)] \left[ \log p(x, z) - \log q_{\phi}(z) \right] \right\}\\
& \text{这里，只有$z$ 为随机变量。对于期望形式的解，我们可以通过采样方式获取其期望}\\
& \text{我们可以从分布}q_{\phi}(z) \text{采集L个样本，以便求出期望}\\
& z^{l} \sim q_{\phi}(z) l = 1, \cdots, L\\
& 对于期望的估计如下\\
& \nabla_{\phi}  \mathcal{L}(\phi) \approx
\frac{1}{L} \sum_{l=1}^{L} \left\{ [\nabla_{\phi} \log q_{\phi}(z^{l})] \left[ \log p(x, z^{l}) - \log q_{\phi}(z^{l}) \right] \right\}\\
& \text{对于}  \log q_{\phi}(z^{l}) \text{由于} q_{\phi}(z^{l}) \text{在 0-1 之间变动, 由} \log \text{函数的性质，该函数的值变动会很大，造成求出的期望方差较大，数值不稳定}
\end{aligned}
$$
## 重参数技巧(Reparameterization Trick)
这里介绍一种解决 期望方差过大 的方法 重参数化技巧
[参考0](https://github.com/WallE-Chang/SGVI/blob/master/SGVI.pdf)
[参考1](https://arxiv.org/pdf/1312.6114.pdf)
[参考2](https://arxiv.org/pdf/1401.0118.pdf)
$$
\begin{aligned}
& 首先证明一个推论：\\
& 若  z \sim q(z),  z = g(\varepsilon), \varepsilon \sim p(\varepsilon) 其中 p(\varepsilon) = q(g(\varepsilon)) g^{'}(\varepsilon)\\
& \varepsilon, z 均为随机变量\\
& 则：\\
& \int f(z) q(z) dz = \int f(z) p(\varepsilon) d \varepsilon, z = g(\varepsilon)\\
& \\
& \\
& 假定 z \sim q(z),  z = g(\varepsilon), \varepsilon \sim p(\varepsilon)\\
& \varepsilon, z 均为随机变量\\
& \int q(z) d z = 1\\
& 由换元积分法 \\
& \int q(g(\varepsilon)) d g(\varepsilon) \\
& \int q(g(\varepsilon)) g^{'}(\varepsilon) d \varepsilon  =  1 = \int p(\varepsilon)  d\varepsilon\\
& 所以 \\
& 可以假定 \\
& p(\varepsilon) = q(g(\varepsilon)) g^{'}(\varepsilon) \\
& 一个实际应用\\
& E_{q(z)}[f(z)] = \int f(z) q(z) dz \\
& 由换元积分法 \\
& \int f(z) q(z) dz = \int f(g(\varepsilon)) q(g(\varepsilon)) dg(\varepsilon)\\
& \Rightarrow \int f(z) q(z) dz = \int f(g(\varepsilon)) q(g(\varepsilon)) g^{'}(\varepsilon) d \varepsilon\\
& \Rightarrow \int f(z) q(z) dz = \int f(g(\varepsilon)) p(\varepsilon) d \varepsilon\\
& \Rightarrow \int f(z) q(z) dz = \int f(z) p(\varepsilon) d \varepsilon, z = g(\varepsilon)\\
& 推论得证
& \\
& \\
& 由以上推论\\
& 令 z = g_{\phi}(\varepsilon)\\
&  \begin{aligned}
\nabla_{\phi}  \mathcal{L}(\phi) &= \nabla_{\phi}  E_{q_{\phi}(z)} \left[ \log p(x, z) - \log q_{\phi}(z) \right]\\
&= \nabla_{\phi}  \int_z  \left[ \log p(x, z) - \log q_{\phi}(z) \right] q_{\phi}(z) d z\\
&=  \nabla_{\phi}  \int_z  \left[ \log p(x, z) - \log q_{\phi}(z) \right] p(\varepsilon)d \varepsilon\\
&= \int_z  \nabla_{\phi} \left[ \log p(x, z) - \log q_{\phi}(z) \right] p(\varepsilon)d \varepsilon\\
&= E_{p(\varepsilon)} \left[ \nabla_{\phi} \left[ \log p(x, z) - \log q_{\phi}(z) \right] \right]\\
&= E_{p(\varepsilon)} \left[ \nabla_{z} \left[ \log p(x, z) - \log q_{\phi}(z) \right] \nabla_{\phi}z\right]\\
&= E_{p(\varepsilon)} \left[ \nabla_{z} \left[ \log p(x, z) - \log q_{\phi}(z) \right] \nabla_{\phi}g_{\phi}(\varepsilon)\right]\\
\end{aligned}\\
& 所以通过对 \varepsilon 采样\\
& \text{我们可以从分布}p(\varepsilon) \text{采集L个样本，以便求出期望}\\
& \varepsilon^{l} \sim p(\varepsilon); l = 1, \cdots, L\\
& 得到期望的估计\\
& \nabla_{\phi}  \mathcal{L}(\phi) \approx
\frac{1}{L} \sum_{l=1}^{L} \left[ \nabla_{z} \left[ \log p(x, z) - \log q_{\phi}(z) \right] \nabla_{\phi}g_{\phi}(\varepsilon^{l})\right], 其中 z = g_{\phi}(\varepsilon^{l})
\end{aligned}
$$

# VI的主要特点
- **假设太强**： $q(z)$ 分为 M 组 以后，每组变量之间相互独立
- 对于复杂问题依旧存在**积分困难**的问题