% Created 2020-04-02 Thu 21:08
% Intended LaTeX compiler: pdflatex
\documentclass[11pt]{article}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{graphicx}
\usepackage{grffile}
\usepackage{longtable}
\usepackage{wrapfig}
\usepackage{rotating}
\usepackage[normalem]{ulem}
\usepackage{amsmath}
\usepackage{textcomp}
\usepackage{amssymb}
\usepackage{capt-of}
\usepackage{hyperref}
\usepackage{ctex}
\author{hyliu}
\date{\today}
\title{高斯分布}
\hypersetup{
 pdfauthor={hyliu},
 pdftitle={高斯分布},
 pdfkeywords={},
 pdfsubject={},
 pdfcreator={Emacs 26.3 (Org mode 9.2.6)}, 
 pdflang={English}}
\begin{document}

\maketitle
\tableofcontents

\section{高斯分布}
\label{sec:org5bffd59}
\subsection{参数估计}
\label{sec:orgb47ac9b}
\subsubsection{问题定义}
\label{sec:org9dbe9ec}
\[
Data : X = (x_1,x_2,...,x_N)^T = \left (\begin{array}{c}
x_{1}^T \\
x_2^T \\
... \\
x_N^T
}
\end{array}
\right )_{N*P}
\]
\[
x_i \in \mathbb{R}^{P}
\]
\[
x_i \sim \mathcal{N}(\mu,\Sigma)
\] 
\[
\theta = (\mu,\Sigma)
\]
\subsubsection{高斯分布公式}
\label{sec:orgb6f6467}
\begin{enumerate}
\item 一维高斯分布公式
\end{enumerate}
\[
   P(x) = \frac{1}{\sqr{2\pi} \sigma} \exp (-\frac{(x-\mu)^2}{2\sigma^2})
 \]
\begin{enumerate}
\item 多维高斯分布公式
\end{enumerate}

\begin{equation}
\label{eq:3}
 P(x) = \frac{1}{(2\pi)^{\frac{1}{P}}\left| \Sigma \right|^{\frac{1}{2}}} \exp (-\frac{1}{2}(x-\mu)^T\Sigma^{-1}(x-\mu))
\end{equation}
\(\Sigma\) 为协方差矩阵

\subsubsection{Maximum likelihood estimation (MLE)}
\label{sec:org8bd9231}
\[
\theta_{MLE} = \arg\max_{\theta} P(X|\theta)
\]
当 \(P = 1\), \(\theta = (\mu, \sigma^{2})\)

\subsubsection{公式推导}
\label{sec:org5a615a4}
\begin{equation}
\begin{align}
\label{eq:4}
\log P(X|\theta) &= log \sum_{i=1}^N P(x_i|\theta) = \sum\limits_{i=1}^N \log P(x_i|\theta)\\
&= \sum\limits_{i = 1}^N \log \frac{1}{\sqr{2\pi}\sigma} \exp( -\frac{(x_i-\mu)}{2\sigma^{2}})\\
&= \sum\limits_{i=1}^N \left[ \log \frac{1}{ \sqrt{2\pi}} + log \frac{1}{\sigma} - \frac{\left( x_i -\mu \right)^2}{2\sigma^2} \right]
\end{align}
\end{equation}

\(\mu_{MLE}\) 是无偏估计, \(\sigma_{MLE}\) 是有偏估计。
\begin{enumerate}
\item \(\mu_{MLE}\) 推导
\label{sec:org9000bbb}
\begin{equation}
\begin{align}
\label{eq:5}
\mu_{MLE} &= \arg \max_{\mu} \log P(X|\theta) \\
&= \arg \max_{\mu} \sum\limits_{i=1}^N {-\frac{\left( x_i -\mu \right)^2}{2\sigma^2}}\\
&= \arg \min_{\mu} \sum\limits_{i=1}^N {\left( x_i - \mu \right)^2}
\end{align}
\end{equation}
\begin{equation}
\label{eq:6}
\begin{align}
\frac{\partial}{\partial \mu} \sum \left( x_i - \mu \right)^2 &= \sum\limits_{i=1}^N 2*\left( x_i - \mu \right)*(-1) = 0\\
\sum\limits_{i=1}^N \left( x_i - \mu \right) &= 0 \\
\sum\limits_{i=1}^N x_i - \sum\limits_{i=1}^N \mu &= 0 \\
N*\mu = \sum\limits_{i=1}^N x_i &\\
\mu_{MLE} = \frac{1}{N} \sum\limits_{i=1}^N x_i & 
\end{align}
\end{equation}
\[
E \left( \mu_{MLE} \right) = \frac{1}{N} \sum\limits_{i=1}^N E[x_i]  = \frac{1}{N} \sum\limits_{i=1}^{N} \mu = \mu 
\]

\item \(\sigma_{MLE}\) 推导
\label{sec:orga465625}
\begin{equation}
\begin{align}
\label{eq:2}
\sigma_{MLE}^2 &= \arg \max_{\sigma} P(X|\theta) \\
&= \arg\max_{\sigma} \sum\limits_{i=1}^N (- \log \sigma - \frac{\left( x_i-\mu_i \right)^2}{2\sigma^2})
\end{align}
\end{equation}
\begin{equation}
\begin{align}
\label{eq:8}
&\mathcal L(\sigma) =  - \log \sigma - \frac{\left( x_i-\mu_i \right)^2}{2\sigma^2} \\
&\frac{\partial \mathcal L}{\partial\sigma} = \sum\limits_{i=1}^N \left[ -\frac{1}{\sigma} + \sigma^{-3} \left( x_i -\mu \right)^{2}\right] \\
&\sum\limits_{i=1}^N \left[ -\sigma^2 + \left( x_i -\mu \right)^2  \right] = 0\\
& -N\sigma^2 + \sum\limits_{i=1}^N \left( x_i -\mu \right)^2 = 0 \\
& \sigma_{MLE}^2 = \frac{1}{N} \sum\limits_{i=1}^N \left( x_i - \mu_{MLE} \right)^{2}
\end{align}
\end{equation}
\[
\sigma_{MLE}^{2} = \frac{1}{N} \sum\limits_{i=1}^N \left( x_i - \mu_{MLE} \right)^{2} = \frac{1}{N} \sum\limits_{i=1}^N \left( x_i^2 - 2x_i \mu_{MLE} + \mu_{MLE}  \right)\\
= \frac{1}{N} \sum\limits_{i=1}^N x_i^2 - \frac{1}{N} \sum\limits_{i=1}^N 2 x_i \mu_{MLE} + \frac{1}{N} \sum\limits_{i=1}^N \mu_{MLE}^2  
= \frac{1}{N} \sum\limits_{i=1}^N x_i^2 - 2 \mu_{MLE}^2 + \mu_{MLE}^2 = \frac{1}{N} \sum\limits_{i=1}^N x_i^2 - \mu_{MLE}^{2} 
\]
\[
Var(\mu_{MLE}) = Var(\frac{1}{N}\sum\limits_{i=1}^N x_i) = \frac{1}{N^2} \sum\limits_{i=1}^N Var(x_i) = \frac{1}{N} Var(x_i) = \frac{1}{N} \sigma^2
\]
\begin{equation}
\begin{align}
\label{eq:9}
E[\sigma_{MLE}^2] &= E[\frac{1}{N} \sum\limits_{i=1}^N x_i^2 - \mu_{MLE}^2] = E[(\frac{1}{N}\sum\limits_{i=1}^N x_i^2 - \mu^2) - \left( \mu_{MLE}^2 -\mu^2 \right)] \\
&= E[\frac{1}{N} \sum\limits_{i=1}^N x_i^2 -\mu^2] - E(\mu_{MLE}^2 - \mu^2)\\
&= [\frac{1}{N} \sum\limits_{i=1}^N E(x_i^2 - \mu^2)] - [E(\mu_{MLE}^2) - E(\mu^2)]\\
&= [\frac{1}{N} \sum\limits_{i=1}^N (E(x_i^2) - \mu^2)] - [E(\mu_{MLE}^2) - \mu^2] \\
&= [\frac{1}{N} \sum\limits_{i=1}^N (Var(x_i))] - [E(\mu_{MLE}^2) - E(\mu_{MLE}^2)^{2}]\\
&= [\sigma^{2}] - [Var(\mu_{MLE})]\\
&= [\sigma^2] - [\frac{1}{N} \sigma^2]\\
&= \frac{N-1}{N} \sigma^2
\end{align}
\end{equation}

\[
E(\sigma_{MLE}) = \frac{N-1}{N} \sigma^2 
\]

\[
\sigma^{2} = \frac{1}{N-1} \sum\limits_{i=1}^N \left( x_i - \mu_{MLE} \right)^{2}
\]
\end{enumerate}

\subsection{Linear Gaussian Model (线性高斯模型)}
\label{sec:org6c0a7f3}
\subsection{有偏误差在贝叶斯网络中的体现}
\label{sec:org21eda2c}
\end{document}