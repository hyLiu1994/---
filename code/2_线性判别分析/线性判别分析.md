- 三种线性判别分析 
  - A linear_discriminant_analysis.py 使用的目标函数为 $J \left( w \right) = \frac{w^T S_b w}{w^T S_w w}$
  - B linear_discriminant_analysis_KL.py 使用的目标函数为 两个类别分布的KL散度
  - C linear_discriminant_analysis_minus.py 使用的目标函数为 第一种的变体，由除法改为减法
$J \left( w \right) = w^T S_b w - w^T S_w w$
- 通过对三种实现方式在随机生成的数据集中的结果来看 
$$A \approx B > C$$
- 实验结果分析
A 为经典的线性判别分析的优化目标，C为一种变体，但是这种变体并无意义，无法说明该变体在设计目的，还是算法性能方面优于A
B 与 A 几乎一致，B的设计主要来源于最近所学概率模型的知识。
通过最大化KL散度希望两个分布差别最大，但是这种优化目标与**类间大，类内小** 还有些差异，极大化KL散度应该也可以通过其他途径，所以我觉得这个优化目标**还是有一些问题**（虽然在模拟数据上面同经典算法结果一致）。
