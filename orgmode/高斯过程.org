* 高斯过程
** 核心思想
高斯过程是定义在连续域上的无限多个高维随机变量所组成的随机过程。 (连续域指时间或空间)
目的是建模隐变量为连续的随机过程。
#+BEGIN_SRC ditaa :file ./Figure/GaussianProcess.png
  Gaussian Dist  -------->    Multivariate Gaussian Dist   -------->  无限维 Gaussian Dist 
    一维高斯分布                          
                                         ^                                     ^
                                         |                                     |
                                         |                                     |
                                         V                                     V
                                  Guassian Network                      Guassian Process
                                     高斯网络                               高斯过程
#+END_SRC

#+RESULTS:
[[file:./Figure/GaussianProcess.png]]
** 定义
$\left\{ X_t \right\}_{t\in T}$, T -> 连续域, 如果 $\forall n \in N^+, \quad t_1, t_2, ..., t_n \in T$, $s.t. \left\{ X_{t_1}, X_{t_2},...,X_{t_n}\right\} \triangleq X_{t_1 - t_n} \sim \mathcal{N} \left( \mu_{t_1-t_n}, \Sigma_{t_1 - t_n} \right)}$, 那么 $\left\{ X_t \right\}_{t \in T}$ 就是一个高斯过程。
$GP \left( m(t), k(s,t) \right)$ 表示一个高斯过程, 其中 $\left \{\begin{array}{l}m(t) E \left[ X_t \right]\\ k \left( s,t \right) = E \left[ (X_s - m(s)) (X_t - m(t))^T \right]  \end{array}\right$
** 高斯过程回归
Gaussian Process Regression is the extension of Bayesian Linear Regression with kernel trick.
*** 权重空间视角(weight-space view) 
#+BEGIN_SRC ditaa :file ./Figure/BayesianLinearRegression.png
                     +-> 1. Non-linear Transformation -+
  Non linear  -------+                                 +->  ---kernel method----> kernel BLR
                     +-> 2. Bayesian LR               -+                               ^
                                                                                       |
                                                                                       |
                                                                                       V
                                                                           Guassian Linear Regression
#+END_SRC
#+RESULTS:
[[file:./Figure/BayesianLinearRegression.png]]

If $\Phi: x\rightarrow z, x\in \mathbb{R}^{p}, z= \phi(x) \in \mathbb{R}^q, q>p$
Define: $\Phi = \phi(x) = (\phi(x_1), \phi(x_2),..., \phi(x_N))^T_{N\timesq}$
Then: $f(x) = \phi(x)^T w$, $f(x^{*})| X, Y, x^{*} \sim \mathcal{N} \left( \sigma^2 \phi(x^{* })^T A^{-1} \Phi^T Y, \phi(x^{* }) A^{-1} \phi(x^{* }) \right)$, 其中 $A = \sigma^{-2} \Phi^T \Phi + \Sigma_p^{-1}$
**** 将 $A$ 带入均值与方差公式 
\begin{align*}
A &= \sigma^{-2} \Phi^T \Phi + \Sigma_p^{-1}\\
A \Sigma_p &= \sigma^{-2} \Phi^T \Phi \Sigma_p + I\\
A \Sigma_p \Phi^T &= \sigma^{-2} \Phi^T \Phi \Sigma_p \Phi^T + \Phi^T\\
&= \sigma^{-2} \Phi^T (K + \sigma^2 I )\\
\Sigma_p \Phi^T &= \sigma^2 A^{-1} \Phi^T \left( K + \sigma^2 I \right)\\
\sigma^2 A^{-1} \Phi^T  &= \Sigma_p \Phi^T \left( K + \sigma^2 I \right)^{-1}\\
\underbrace{\sigma^2 \phi(x^{* }) A^{-1} \Phi^T Y }_{f(x^{* })| X, Y, X^{* } \text{'s expectation}}  &= \phi(x^{* }) \Sigma_p \Phi^T \left( K + \sigma^2 I \right)^{-1} Y \\
\end{align*}

\end{align*}
$f(x^{* }) | X, Y, X^{* } \text{'s covarience}: \phi(x^{* })^T \Sigma_p \phi(x^{* }) - \phi(x^{* })^T \Sigma_p \Phi^T (K + \sigma^2 I)^{-1} \Phi \Sigma_p \Phi(x^{* })$

所有的 K, $\phi(x^{* }) \Sigma_p \Phi^T$, $\phi(x^{* })\Sigma_p \phi(x^{* })$, $\Phi \Sigma_p \phi(x^{* })$ 都可以转化为 $\phi(x)^T \Sigma_p \phi(x')$ 的形式.
\begin{align*}
&\because \Sigma_p: \text{positive definite}, \Sigma_p = \left( \Sigma_p^{\frac{1}{2}} \right)^2\\ 
&\therefore K \left( x, x' \right) = \phi(x)^T \Sigma_p^{\frac{1}{2}} \Sigma_p^{\frac{1}{2}} \phi(x') = \left( \Sigma_p^{\frac{1}{2}} \phi(x) \right)^T \Sigma_p^{\frac{1}{2}} \phi(x') = < \psi(x), \psi(x') >
\end{align*}
因此可以通过核方法来进行加速计算.
**** 线性代数知识点
***** Woodbury Formula
\begin{equation}
\label{eq:6}
\left( A + UCV \right)^{-1} = A^{-1} - A^{-1} U (C^{-1} + V A^{-1} U)^{-1} V A^{-1}
\end{equation}
*** 函数空间视角(function-space view)




